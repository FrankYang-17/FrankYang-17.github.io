---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# üë®‚Äçüéì About Me
I am a second-year Ph.D. student at Peking University, advised by Prof. Xuejun Yang and Prof. Wenjing Yang. I earned my B.S. degree at China University of Geosciences in 2023. Prior to this, I served in the People's Liberation Army of China from 2017 to 2019.

My primary research interest focus on **Foundation Models for Multimodal Learning**. I am also interested in **Causal Inference** and **Reinforcement Learning**.

Currently I am working on **Efficient Pretraining and Fine-tuning of Multimodal Large Language Models** and **Unified Models (Any-to-Any)**.

*If you are interested in partnering on research projects, offering internship opportunities or exchange programs, I would be thrilled to connect with you.* üòÑ


# üìù Publications
<span style="font-size: 90%;">*\* Equal Contribution, ‚Ä† Corresponding Author, ‚Ä° Project Leader, # Core Contribution*</span>
- [Mavors: Multi-granularity Video Representation for Multimodal Large Language Model](https://mavors-mllm.github.io/)<br><span style="font-size: 80%;">***Yang Shi**\*, Jiaheng Liu\*, Yushuo Guan\*, Zhenhua Wu, Yuanxing Zhang‚Ä†, Zihao Wang, Weihong Lin, Jingyun Hua, Zekun Wang, Xinlong Chen, Bohan Zeng, Wentao Zhang, Fuzheng Zhang, Wenjing Yang, Di Zhang*</span>
- [MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models](https://arxiv.org/abs/2504.03641)<br><span style="font-size: 80%;">*Wulin Xie\*, Yi-Fan Zhang\*‚Ä°, Chaoyou Fu, **Yang Shi**, Bingyan Nie, Hongkai Chen, Zhang Zhang, Liang Wang, Tieniu Tan*</span>
- [MM-RLHF: The Next Step Forward in Multimodal LLM Alignment](https://arxiv.org/abs/2502.10391)<br><span style="font-size: 80%;">*Yi-Fan Zhang‚Ä°, Tao Yu, Haochen Tian, Chaoyou Fu‚Ä†, Peiyan Li, Jianshu Zeng, Wulin Xie, **Yang Shi**, Huanyu Zhang, Junkang Wu, Xue Wang, Yibo Hu, Bin Wen‚Ä†, Fan Yang, Zhang Zhang‚Ä†, Tingting Gao, Di Zhang, Liang Wang, Rong Jin, Tieniu Tan*</span>
- [EmbodiedEval: Evaluate Multimodal LLMs as Embodied Agents](https://arxiv.org/abs/2501.11858v1)<br><span style="font-size: 80%;">*Zhili Cheng‚Ä°, Yuge Tu\#, Ran Li\#, Shiqi Dai\#, Jinyi Hu\#‚Ä°, Shengding Hu, Jiahao Li, **Yang Shi**, Tianyu Yu, Weize Chen, Lei Shi, Maosong Sun‚Ä†*</span>


# üë®‚Äçüíª Work Experience
- Research Intern at *KLING*, **Kuaishou Technology**, 2025.04 - Present
- Research Intern at *KwaiYii*, **Kuaishou Technology**, 2025.02 - 2025.04
- Research Intern at *THUNLP*, **Tsinghua University**, 2023.11 - 2025.02


# üìö Education
- **Ph.D.** School of Computer Science, **Peking University**, 2023 - Present
- **B.S.** School of Computer Science, **China University of Geosciences**, 2019 - 2023


# üåü Honors & Awards
- Ruiming Alumni Scholarship, **1‚Ä∞** , 2021
- China National Scholarship, **0.2%** , 2020